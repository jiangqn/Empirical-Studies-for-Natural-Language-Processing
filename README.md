# Empirical-Studies-for-Natural-Language-Processing
A resources list of empirical studies and investigations for natural language processing.

- **[ACL-18]** How Much Attention Do You Need? A Granular Analysis of Neural Machine Translation Architectures. [[paper]](https://www.aclweb.org/anthology/P18-1167.pdf)

- **[ACL-18]** The Best of Both Worlds: Combining Recent Advances in Neural Machine Translation. [[paper]](https://www.aclweb.org/anthology/P18-1008.pdf)

- **[EMNLP-18]** Why Self-Attention? A Targeted Evaluation of Neural Machine Translation Architectures. [[paper]](https://www.aclweb.org/anthology/D18-1458.pdf)

- **[EMNLP-18]** An Empirical Study of Machine Translation for the Shared Task of WMT18. [[paper]](https://www.aclweb.org/anthology/W18-6404.pdf)

- **[ACL-19]** Do Neural Dialog Systems Use the Conversation History Effectively? An Empirical Study. [[paper]](https://www.aclweb.org/anthology/P19-1004.pdf) [[code]](https://github.com/chinnadhurai/ParlAI/)

- **[ACL-19]** Revisiting Low-Resource Neural Machine Translation:A Case Study. [[paper]](https://www.aclweb.org/anthology/P19-1021.pdf)
> This paper shows that the performance of NMT model can be improved by a large margin through carefully hyper-paramaters tuning. Reducing BPE vocabulary size and word dropout are most useful tricks to improve the performance of NMT models when little parallel corpus is available.

- **[EMNLP-19]** An Empirical Comparison on Imitation Learning and Reinforcement Learning for Paraphrase Generation. [[paper]](https://arxiv.org/pdf/1908.10835.pdf)

- **[EMNLP-19]** An Empirical Study of Incorporating Pseudo Data into Grammatical Error Correction. [[paper]](https://arxiv.org/pdf/1909.00502.pdf)

- **[EMNLP-19]** Investigating the Effectiveness of BPE: The Power of Shorter Sequences. [[paper]](https://www.aclweb.org/anthology/D19-1141.pdf)

- **[EMNLP-19]** Are We Modeling the Task or the Annotator? An Investigation of Annotator Bias in Natural Language Understanding Datasets. [[paper]](https://www.aclweb.org/anthology/D19-1107.pdf)

- **[arXiv-19]** An Empirical Study of Generation Order for Machine Translation. [[paper]](https://128.84.21.199/pdf/1910.13437.pdf)

- **[arXiv-19]** Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer. [[paper]](https://arxiv.org/abs/1910.10683)
